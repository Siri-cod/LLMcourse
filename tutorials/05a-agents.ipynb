{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siri-cod/LLMcourse/blob/main/tutorials/05a-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWSpvw3L1Ngj"
      },
      "source": [
        "Sheet 5.1 LLM agents\n",
        "==========\n",
        "**Author:** Polina Tsvilodub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLg-qWbQ1Ngl"
      },
      "source": [
        "This sheet takes a closer look at more complex LLM-based systems and *LLM agents*. Specifically, we will use the package [`langchain`](https://python.langchain.com/v0.2/docs/tutorials/) and its extensions to build our own LLM systems and explore their functionality. The learning goals for this sheet are:\n",
        "\n",
        "* understanding basics of langchain\n",
        "* trying out langchain agents and tools\n",
        "* understanding the basics of output processing\n",
        "* familiarization with basic handling of agent memory\n",
        "\n",
        "Langchain is under heavy development. Sometimes examples provided in the docs break with version updates, so one needs to be somewhat patient.\n",
        "\n",
        "**NOTE**: At this point it provides quite vast functionality (and docs, respectively) -- of course, we do NOT expect you to study or understand all of that. The examples below will provide links to some relevant parts of the documentation, and the examples serve a little demo / inspiration of what is out there, as a starting point for you to learn more, if you are interested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjyCxXiw1Ngl"
      },
      "source": [
        "## LangChain\n",
        "\n",
        "The lecture discussed that modern LLMs can be viewed as building blocks of larger systems, be it for engineering or research purposes. In particular, one might want to use an LLM and make several calls (i.e., several inference passses) to it, and somehow use the predicted results together to complete one's task. Note that when we talk about such systems, we (almost always) use the LLM for *inference*, i.e., the LLM is already pretrained / fine-tuned.\n",
        "\n",
        "Using the terminology of langchain, a sequence of such LLM calls is called a *chain*. For each call, one minimally needs to specify a (pretrained / fine-tuned) LLM and a prompt that specifies what exactly the call should accomplish. For the prompt, oftentimes *prompt templates* are used. These prompt templates usually specify *variables* which are filled with inputs when the respective LLM call is invoked. The idea behind this is that the calls can be re-used, e.g., with various user inputs, without having to re-type the entire prompt. Further, these inputs may come from a previous LLM call. One neat feature of langchain is that it allows to seamlessly chain LLM calls and stream outputs from one call into the next. Specific types of templates (e.g., chat prompt templates) also take care of formatting text in the way expected by the model, e.g., adding the required special tokens and format for chat models.\n",
        "\n",
        "[Disclaimer: Not sponsored by LangChain -- there are other very useful tools for doing such things, for instance, [Haystack](https://github.com/deepset-ai/haystack). This is just one popular example.]\n",
        "\n",
        "Below, we will first look at a an example of a simple sequence of LLM calls. In particular, we will build a system that helps us to come up with a dinner menu, given some ingredients that we already have.\n",
        "\n",
        "We will be using the NVIDIA API to get access to performant models for optimal performance. Instructions for retreiving the an API key will be provided in class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "w6RWDEA01Ngl",
        "outputId": "44aa02b5-b9da-440e-d9f2-04e562a100e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_nvidia_ai_endpoints==0.3.9 in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.11/dist-packages (0.1.21)\n",
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.0.4)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (0.3.65)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.4.20250611)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "# please install the following packages and versions\n",
        "\n",
        "!pip install langchain-community langchain-openai langchain_nvidia_ai_endpoints==0.3.9 langchainhub duckduckgo-search wikipedia python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wDtzXBd31Ngm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "44BsFojJ1Ngm"
      },
      "outputs": [],
      "source": [
        "# set some hyperparameters for the generation\n",
        "temperature = 0.7 #控制生成文本的随机性-0保守，1随机\n",
        "kwargs = {\n",
        "    \"max_tokens\": 100, #最大生成长度\n",
        "}\n",
        "# define which model to query\n",
        "MODEL_NAME = \"meta/llama-3.3-70b-instruct\"\n",
        "\n",
        "ingredients = \"cauliflower, tomatoes.\"\n",
        "\n",
        "instructions_text_appetizer = \"I have the following ingredients in my fridge: \\n{ingredients}\\n\\nWhich Italian appetizer can I make for dinner with these ingredients?\"\n",
        "\n",
        "instructions_text_main = \"I am planning to make the following appetizer: \\n{appetizer}\\n\\nWhich Italian main course can I make for my dinner?\"\n",
        "\n",
        "instructions_menu_summary = \"I am planning the following recipes for my dinner: \\nAppetizer: {appetizer}\\nMain course: {main_course}\\n\\nPlease write a menu summary for my dinner.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "urAfUiCl1Ngm",
        "outputId": "bdad5772-4ee3-4f40-a0e0-694b4a4cfe4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:  Here's a menu summary for your dinner:\n",
            "\n",
            "**Appetizer:** Cauliflower and Tomato Bruschetta - toasted bread topped with roasted or sautéed cauliflower, chopped tomatoes, olive oil, salt, and basil.\n",
            "\n",
            "**Main Course:** [To be determined] - please select one of the following traditional Italian options:\n",
            "1. Spaghetti Bolognese\n",
            "2. Chicken or Veal Parmesan\n",
            "3. Risotto alla Milanese\n",
            "4. Pollo alla Cacciatora\n",
            "5. Lasagna\n",
            "\n",
            "Alternatively, you can also consider other options such as seafood or vegetarian dishes. Please let me know your preference to finalize the main course.\n",
            "\n",
            "Buon appetito!\n"
          ]
        }
      ],
      "source": [
        "NVIDIA_API_KEY='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'\n",
        "\n",
        "# instantiate model\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=35 / 60,  # 35 requests per minute to be sure\n",
        "    check_every_n_seconds=0.1,  # wake up every 100 ms to check whether allowed to make a request,\n",
        "    max_bucket_size=7,  # controls the maximum burst size\n",
        ")\n",
        "\n",
        "llm = ChatNVIDIA(\n",
        "      model=MODEL_NAME,\n",
        "      api_key=NVIDIA_API_KEY,\n",
        "      temperature=0,   # ensure reproducibility,\n",
        "      rate_limiter=rate_limiter  # bind the rate limiter\n",
        "  )\n",
        "\n",
        "# construct prompts for our calls\n",
        "prompt_template_appetizer = PromptTemplate(\n",
        "    template = instructions_text_appetizer,\n",
        "    input_variables = ['ingredients'],\n",
        ")\n",
        "prompt_template_main = PromptTemplate(\n",
        "    template = instructions_text_main,\n",
        "    input_variables = ['appetizer'],\n",
        ")\n",
        "prompt_template_summary = PromptTemplate(\n",
        "    template = instructions_menu_summary,\n",
        "    input_variables = ['appetizer', 'main_course'],\n",
        ")\n",
        "# construct sub-chains for each course\n",
        "appetizer_chain = prompt_template_appetizer | llm | StrOutputParser()\n",
        "main_chain = {\"appetizer\": appetizer_chain} | prompt_template_main | llm | StrOutputParser()\n",
        "composed_chain = {\"appetizer\": appetizer_chain, \"main_course\": main_chain} | prompt_template_summary | llm | StrOutputParser()\n",
        "\n",
        "# actually call the execution of the entire chain\n",
        "composed_result = composed_chain.invoke({\"ingredients\": ingredients}) #最初输入\n",
        "print(\"Result: \", composed_result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9HUYSqb1Ngn"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.1: LLM chain</span></strong>\n",
        ">\n",
        "> 1. Please look at the code above and try to understand what it does. Relevant docs about LLM calls can be found [here](https://python.langchain.com/docs/how_to/#prompt-templates), about chains [here](https://python.langchain.com/docs/how_to/sequence/).\n",
        "> 2. Add a third course to our menu! Of course, you can also play around with the other prompts and the sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5xpPTvY_MRa"
      },
      "source": [
        "### Excercise 5.1.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM_T41xm_wwC",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# set some hyperparameters for the generation\n",
        "temperature = 0.7\n",
        "kwargs = {\n",
        "    \"max_tokens\": 100,\n",
        "}\n",
        "\n",
        "ingredients = \"cauliflower, tomatoes.\"\n",
        "\n",
        "instructions_text_appetizer = \"I have the following ingredients in my fridge: \\n{ingredients}\\n\\nWhich Italian appetizer can I make for dinner with these ingredients?\"\n",
        "\n",
        "instructions_text_main = \"I am planning to make the following appetizer: \\n{appetizer}\\n\\nWhich Italian main course can I make for my dinner?\"\n",
        "\n",
        "instructions_text_dessert = \"I am planning to make the following appetizer: \\n{appetizer}\\n\\nWhich dessert can I make for my dinner?\"\n",
        "\n",
        "instructions_menu_summary = \"I am planning the following recipes for my dinner: \\nAppetizer: {appetizer}\\nMain course: {main_course}\\nDessert: {dessert}\\n\\nPlease write a menu summary for my dinner.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Jc7tHn1Ngn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBP_Z4YL_Qjd",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# construct prompts for our calls\n",
        "prompt_template_appetizer = PromptTemplate(\n",
        "    template = instructions_text_appetizer,\n",
        "    input_variables = ['ingredients'],\n",
        ")\n",
        "prompt_template_main = PromptTemplate(\n",
        "    template = instructions_text_main,\n",
        "    input_variables = ['appetizer'],\n",
        ")\n",
        "prompt_template_dessert = PromptTemplate(\n",
        "    template = instructions_text_main,\n",
        "    input_variables = ['main_course'],\n",
        ")\n",
        "\n",
        "prompt_template_summary = PromptTemplate(\n",
        "    template = instructions_menu_summary,\n",
        "    input_variables = ['appetizer', 'main_course', 'dessert'],\n",
        ")\n",
        "# construct sub-chains for each course\n",
        "appetizer_chain = prompt_template_appetizer | llm | StrOutputParser()\n",
        "main_chain = {\"appetizer\": appetizer_chain} | prompt_template_main | llm | StrOutputParser()\n",
        "dessert_chain = {\"appetizer\": appetizer_chain, \"main_course\": main_chain} | prompt_template_main | llm | StrOutputParser()\n",
        "composed_chain = {\"appetizer\": appetizer_chain, \"main_course\": main_chain, \"dessert\": dessert_chain} | prompt_template_summary | llm | StrOutputParser()\n",
        "\n",
        "# actually call the execution of the entire chain\n",
        "composed_result = composed_chain.invoke({\"ingredients\": ingredients})\n",
        "print(\"Result: \", composed_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjX9LZTj1Ngn"
      },
      "source": [
        "### Agents\n",
        "\n",
        "In the system above, we have decomposed the task of creating a dinner menu into \"bite-sized\" pieces for LLM calls ourselves; i.e., we have specified the order and the specific prompt for the single calls ourselves. Next, we will try to avoid these steps, and use an *agent* instead: i.e., we will pass our overall task description to an LLM and let it figure out the necessary substeps on its own. Specifically, we will use a [React agent](https://react-lm.github.io/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si4uuswL1Ngn"
      },
      "outputs": [],
      "source": [
        "# same task with agent\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import create_react_agent\n",
        "\n",
        "# Get an example prompt from langchain that was constructed for this agent architecture. you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "# inspect the prompt\n",
        "prompt.template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGCFx2kS1Ngn"
      },
      "source": [
        "For most modern out of the box agents, the agent instantiation accepts a list of *tools*. The agent tried to make use of the tools above. Below, we add such tools to the agent -- specifically, we will provide it with a tool to call the Wikipedia API anf to a search API for real time searches.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiQgqoa61Ngn"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "tools = load_tools([\"wikipedia\"], llm=llm)\n",
        "tools.append(search)\n",
        "print('tools',  tools)\n",
        "\n",
        "# create an agent with tools\n",
        "agent_with_tools = create_react_agent(llm, tools=tools, prompt=prompt)\n",
        "\n",
        "# instantiate and call the agent\n",
        "agent_executor = AgentExecutor(agent=agent_with_tools, tools=tools, verbose=True)\n",
        "agent_executor.invoke({\"input\": \"Please help me come up with a three course Italian dinner menu. It should be vegetarian. I have cauliflower and tomatoes in my fridge.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZE_nik11Ngo"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.3: LLM agents with tools</span></strong>\n",
        ">\n",
        "> 1. Please look at the code above and try to understand what it does. A list of various tools can be found here [here](https://python.langchain.com/docs/integrations/tools/).\n",
        "> 2. What steps does the agent (try to) perform in order to accomplish the task? How does it \"know\" which steps to do when? When does it execute searhces?\n",
        "> 3. Compare the results to the chain above. Do you observe differences?\n",
        "> 4. Is the Wikipedia tool a good choice for the task at hand? What else might we consider?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQqB5AKw1Ngo"
      },
      "source": [
        "```{toggle}\n",
        "> 2. The model is searching stepwise. In the firt step it searches for the whole information, getting more concrete from step to step. It even focuses on specific ingredients, like a human would do.\n",
        "> 3. The results the model found are vegetarian, using the given ingredients and are italien. Therefore, the results are better than the outputs from the models before.\n",
        "> 4. Wikipedia is interesting for theoretical information about italian food and vegetarian food, but does not provide detailed recipies. The possibilities are rather limited. Therefore, a tool concentrating on recipies might be helpful to get a better variety of recipies. Nonetheless, the results the model found are better than the results of the other models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riQ2Di511Ngo"
      },
      "source": [
        "For the sake of seeing the top possible performance of agents, we have used OpenAI models. But since they are behind a paywall, we might also want to use open-source models as a backbone for the agent. LangChain also provides integration with many [various](https://python.langchain.com/v0.1/docs/integrations/llms/) LLMs, including HuggingFace models that can be used via the HF [API endpoint](https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_endpoint/) which might not always be available and requires and HuggingFace [account](https://huggingface.co/welcome), or with a [local](https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_pipelines/) model loaded via `transformers` as we have learned. The latter requires downloading the model; since agent LLM systems require good performance of the backbone LLM, it can rather be tested with large models with at least a few billion parameters (mind their size for downloads!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wknp-m7o1Ngo"
      },
      "source": [
        "## Output parsing\n",
        "\n",
        "One of the core bottlenecks of chaining LLM calls is the potential necessity to *process outputs* in a specific (structured) way. [This](https://python.langchain.com/docs/how_to/structured_output/) page provides an overview of how this can be approached. This is step is key for enabling integration of LLMs into automatic systems where other components depend on outputs of LLMs and usually expect particular input types or formats.\n",
        "\n",
        "There are also packages / frameworks specialized in interfacing with LLMs and properly parsing their outputs like, e.g., [LMQL](https://lmql.ai/) and [this](https://github.com/microsoft/aici) controller framework from Microsoft.\n",
        "\n",
        "These resources are intended as optional useful information, in case you will explore and build your own agents; you are not expected to have looked at them in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbb9pzzz1Ngo"
      },
      "source": [
        "## Memory handling\n",
        "\n",
        "One of the main issues of agents is that they are by default *stateless*; i.e., at each step of execution there is no memory of what happened before. This is handled by adding *memory components*. An overview of this can be found [here](https://python.langchain.com/docs/how_to/chatbots_memory/#summary-memory)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDgddLJG1Ngo"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.4: Memory</span></strong>\n",
        ">\n",
        "> 1. Take a look at the approach for handling message memory above. Recall the *generative agent* architecture that was discussed in the lecture. What is the difference between this simple approach and the memory implementation in the generative agents? What are respective (dis)advantages of either approach?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}