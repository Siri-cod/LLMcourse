{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siri-cod/LLMcourse/blob/main/tutorials/05a-agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWSpvw3L1Ngj"
      },
      "source": [
        "Sheet 5.1 LLM agents\n",
        "==========\n",
        "**Author:** Polina Tsvilodub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLg-qWbQ1Ngl"
      },
      "source": [
        "This sheet takes a closer look at more complex LLM-based systems and *LLM agents*. Specifically, we will use the package [`langchain`](https://python.langchain.com/v0.2/docs/tutorials/) and its extensions to build our own LLM systems and explore their functionality. The learning goals for this sheet are:\n",
        "\n",
        "* understanding basics of langchain\n",
        "* trying out langchain agents and tools\n",
        "* understanding the basics of output processing\n",
        "* familiarization with basic handling of agent memory\n",
        "\n",
        "Langchain is under heavy development. Sometimes examples provided in the docs break with version updates, so one needs to be somewhat patient.\n",
        "\n",
        "**NOTE**: At this point it provides quite vast functionality (and docs, respectively) -- of course, we do NOT expect you to study or understand all of that. The examples below will provide links to some relevant parts of the documentation, and the examples serve a little demo / inspiration of what is out there, as a starting point for you to learn more, if you are interested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjyCxXiw1Ngl"
      },
      "source": [
        "## LangChain\n",
        "\n",
        "The lecture discussed that modern LLMs can be viewed as building blocks of larger systems, be it for engineering or research purposes. In particular, one might want to use an LLM and make several calls (i.e., several inference passses) to it, and somehow use the predicted results together to complete one's task. Note that when we talk about such systems, we (almost always) use the LLM for *inference*, i.e., the LLM is already pretrained / fine-tuned.\n",
        "\n",
        "Using the terminology of langchain, a sequence of such LLM calls is called a *chain*. For each call, one minimally needs to specify a (pretrained / fine-tuned) LLM and a prompt that specifies what exactly the call should accomplish. For the prompt, oftentimes *prompt templates* are used. These prompt templates usually specify *variables* which are filled with inputs when the respective LLM call is invoked. The idea behind this is that the calls can be re-used, e.g., with various user inputs, without having to re-type the entire prompt. Further, these inputs may come from a previous LLM call. One neat feature of langchain is that it allows to seamlessly chain LLM calls and stream outputs from one call into the next. Specific types of templates (e.g., chat prompt templates) also take care of formatting text in the way expected by the model, e.g., adding the required special tokens and format for chat models.\n",
        "\n",
        "[Disclaimer: Not sponsored by LangChain -- there are other very useful tools for doing such things, for instance, [Haystack](https://github.com/deepset-ai/haystack). This is just one popular example.]\n",
        "\n",
        "Below, we will first look at a an example of a simple sequence of LLM calls. In particular, we will build a system that helps us to come up with a dinner menu, given some ingredients that we already have.\n",
        "\n",
        "We will be using the NVIDIA API to get access to performant models for optimal performance. Instructions for retreiving the an API key will be provided in class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w6RWDEA01Ngl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c7eee02-fc6c-43d5-e51c-40542cbc631b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain_nvidia_ai_endpoints==0.3.9\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.0.4-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (0.3.65)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.45)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.1)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading duckduckgo_search-8.0.4-py3-none-any.whl (18 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=d8ee37be684eddabcdaebcb5e4ffd2ea2badff28e184a9ef81d4eec17f5ecf21\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: types-requests, python-dotenv, primp, mypy-extensions, marshmallow, httpx-sse, wikipedia, typing-inspect, langchainhub, duckduckgo-search, pydantic-settings, dataclasses-json, langchain-openai, langchain_nvidia_ai_endpoints, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 duckduckgo-search-8.0.4 httpx-sse-0.4.0 langchain-community-0.3.25 langchain-openai-0.3.24 langchain_nvidia_ai_endpoints-0.3.9 langchainhub-0.1.21 marshmallow-3.26.1 mypy-extensions-1.1.0 primp-0.15.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 types-requests-2.32.4.20250611 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# please install the following packages and versions\n",
        "\n",
        "!pip install langchain-community langchain-openai langchain_nvidia_ai_endpoints==0.3.9 langchainhub duckduckgo-search wikipedia python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wDtzXBd31Ngm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_core.rate_limiters import InMemoryRateLimiter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "44BsFojJ1Ngm"
      },
      "outputs": [],
      "source": [
        "# set some hyperparameters for the generation\n",
        "temperature = 0.7 #控制生成文本的随机性-0保守，1随机\n",
        "kwargs = {\n",
        "    \"max_tokens\": 100, #最大生成长度\n",
        "}\n",
        "# define which model to query\n",
        "MODEL_NAME = \"meta/llama-3.3-70b-instruct\"\n",
        "\n",
        "ingredients = \"cauliflower, tomatoes.\"\n",
        "\n",
        "instructions_text_appetizer = \"I have the following ingredients in my fridge: \\n{ingredients}\\n\\nWhich Italian appetizer can I make for dinner with these ingredients?\"\n",
        "\n",
        "instructions_text_main = \"I am planning to make the following appetizer: \\n{appetizer}\\n\\nWhich Italian main course can I make for my dinner?\"\n",
        "\n",
        "instructions_menu_summary = \"I am planning the following recipes for my dinner: \\nAppetizer: {appetizer}\\nMain course: {main_course}\\n\\nPlease write a menu summary for my dinner.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "urAfUiCl1Ngm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41fcd8a-8d9e-4405-f8e2-70d976073375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:  Based on our conversation, here's a menu summary for your dinner:\n",
            "\n",
            "**Appetizer:**\n",
            "You have three options to choose from:\n",
            "1. \"Cavolfiore Fritto con Pomodoro\" (Fried Cauliflower with Tomato)\n",
            "2. \"Cauliflower Fritters with Fresh Tomato Salsa\"\n",
            "3. \"Bruschetta con Cavolfiore e Pomodoro\" (Toasted bread topped with sautéed cauliflower, diced tomatoes, garlic, and olive oil)\n",
            "\n",
            "**Main Course:**\n",
            "You have five Italian-inspired options to choose from:\n",
            "1. Spaghetti Bolognese\n",
            "2. Chicken or Veal Parmesan\n",
            "3. Risotto alla Milanese\n",
            "4. Pollo alla Cacciatora\n",
            "5. Lasagna\n",
            "\n",
            "Please select one option from each course to finalize your dinner menu. I'll be happy to help you with any further questions or modifications!\n"
          ]
        }
      ],
      "source": [
        "NVIDIA_API_KEY='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'\n",
        "\n",
        "# instantiate model\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=35 / 60,  # 35 requests per minute to be sure\n",
        "    check_every_n_seconds=0.1,  # wake up every 100 ms to check whether allowed to make a request,\n",
        "    max_bucket_size=7,  # controls the maximum burst size\n",
        ")\n",
        "\n",
        "llm = ChatNVIDIA(\n",
        "      model=MODEL_NAME,\n",
        "      api_key=NVIDIA_API_KEY,\n",
        "      temperature=0,   # ensure reproducibility,\n",
        "      rate_limiter=rate_limiter  # bind the rate limiter\n",
        "  )\n",
        "\n",
        "# construct prompts for our calls\n",
        "prompt_template_appetizer = PromptTemplate(\n",
        "    template = instructions_text_appetizer,\n",
        "    input_variables = ['ingredients'],\n",
        ")\n",
        "prompt_template_main = PromptTemplate(\n",
        "    template = instructions_text_main,\n",
        "    input_variables = ['appetizer'],\n",
        ")\n",
        "prompt_template_summary = PromptTemplate(\n",
        "    template = instructions_menu_summary,\n",
        "    input_variables = ['appetizer', 'main_course'],\n",
        ")\n",
        "# construct sub-chains for each course\n",
        "appetizer_chain = prompt_template_appetizer | llm | StrOutputParser()\n",
        "main_chain = {\"appetizer\": appetizer_chain} | prompt_template_main | llm | StrOutputParser()\n",
        "composed_chain = {\"appetizer\": appetizer_chain, \"main_course\": main_chain} | prompt_template_summary | llm | StrOutputParser()\n",
        "\n",
        "# actually call the execution of the entire chain\n",
        "composed_result = composed_chain.invoke({\"ingredients\": ingredients}) #最初输入\n",
        "print(\"Result: \", composed_result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9HUYSqb1Ngn"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.1: LLM chain</span></strong>\n",
        ">\n",
        "> 1. Please look at the code above and try to understand what it does. Relevant docs about LLM calls can be found [here](https://python.langchain.com/docs/how_to/#prompt-templates), about chains [here](https://python.langchain.com/docs/how_to/sequence/).\n",
        "> 2. Add a third course to our menu! Of course, you can also play around with the other prompts and the sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5xpPTvY_MRa"
      },
      "source": [
        "### Excercise 5.1.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QM_T41xm_wwC",
        "tags": [
          "hide-cell"
        ]
      },
      "outputs": [],
      "source": [
        "# set some hyperparameters for the generation\n",
        "temperature = 0.7\n",
        "kwargs = {\n",
        "    \"max_tokens\": 100,\n",
        "}\n",
        "\n",
        "ingredients = \"cauliflower, tomatoes.\"\n",
        "\n",
        "instructions_text_appetizer = \"I have the following ingredients in my fridge: \\n{ingredients}\\n\\nWhich Italian appetizer can I make for dinner with these ingredients?\"\n",
        "\n",
        "instructions_text_main = \"I am planning to make the following appetizer: \\n{appetizer}\\n\\nWhich Italian main course can I make for my dinner?\"\n",
        "\n",
        "instructions_text_dessert = \"I am planning to make the following appetizer: \\n{appetizer}\\n\\nWhich dessert can I make for my dinner?\"\n",
        "\n",
        "instructions_menu_summary = \"I am planning the following recipes for my dinner: \\nAppetizer: {appetizer}\\nMain course: {main_course}\\nDessert: {dessert}\\n\\nPlease write a menu summary for my dinner.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Jc7tHn1Ngn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rBP_Z4YL_Qjd",
        "tags": [
          "hide-cell"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4b0143-521c-48e8-9c6a-968865de2d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:  Based on our conversation, here's a summary of your dinner menu:\n",
            "\n",
            "**Appetizer:** Bruschetta con Cavolfiore e Pomodoro (Toasted Bread with Cauliflower and Tomato) - toasted bread topped with sautéed cauliflower and cherry tomatoes, drizzled with olive oil and salt.\n",
            "\n",
            "**Main Course:** You have several options to choose from, including Spaghetti Bolognese, Chicken Parmesan, Risotto alla Milanese, Pollo alla Cacciatora, and Lasagna. Please select one of these options or let me know if you have any other preferences.\n",
            "\n",
            "**Dessert:** Unfortunately, we didn't discuss dessert options yet. Would you like me to suggest some traditional Italian desserts, such as Tiramisù, Panna Cotta, or Gelato?\n",
            "\n",
            "Please let me know your main course selection and if you'd like some dessert suggestions, and I'll be happy to complete your menu summary!\n"
          ]
        }
      ],
      "source": [
        "# construct prompts for our calls\n",
        "prompt_template_appetizer = PromptTemplate(\n",
        "    template = instructions_text_appetizer,\n",
        "    input_variables = ['ingredients'],\n",
        ")\n",
        "prompt_template_main = PromptTemplate(\n",
        "    template = instructions_text_main,\n",
        "    input_variables = ['appetizer'],\n",
        ")\n",
        "prompt_template_dessert = PromptTemplate(\n",
        "    template = instructions_text_main,\n",
        "    input_variables = ['main_course'],\n",
        ")\n",
        "\n",
        "prompt_template_summary = PromptTemplate(\n",
        "    template = instructions_menu_summary,\n",
        "    input_variables = ['appetizer', 'main_course', 'dessert'],\n",
        ")\n",
        "# construct sub-chains for each course\n",
        "appetizer_chain = prompt_template_appetizer | llm | StrOutputParser()\n",
        "main_chain = {\"appetizer\": appetizer_chain} | prompt_template_main | llm | StrOutputParser()\n",
        "dessert_chain = {\"appetizer\": appetizer_chain, \"main_course\": main_chain} | prompt_template_dessert | llm | StrOutputParser()\n",
        "composed_chain = {\"appetizer\": appetizer_chain, \"main_course\": main_chain, \"dessert\": dessert_chain} | prompt_template_summary | llm | StrOutputParser()\n",
        "\n",
        "# actually call the execution of the entire chain\n",
        "composed_result = composed_chain.invoke({\"ingredients\": ingredients})\n",
        "print(\"Result: \", composed_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjX9LZTj1Ngn"
      },
      "source": [
        "### Agents\n",
        "\n",
        "In the system above, we have decomposed the task of creating a dinner menu into \"bite-sized\" pieces for LLM calls ourselves; i.e., we have specified the order and the specific prompt for the single calls ourselves. Next, we will try to avoid these steps, and use an *agent* instead: i.e., we will pass our overall task description to an LLM and let it figure out the necessary substeps on its own. Specifically, we will use a [React agent](https://react-lm.github.io/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "si4uuswL1Ngn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "b185cce6-a34f-499c-e608-057d0229bb97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# same task with agent\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.agents import create_react_agent\n",
        "\n",
        "# Get an example prompt from langchain that was constructed for this agent architecture. you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "# inspect the prompt\n",
        "prompt.template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGCFx2kS1Ngn"
      },
      "source": [
        "For most modern out of the box agents, the agent instantiation accepts a list of *tools*. The agent tried to make use of the tools above. Below, we add such tools to the agent -- specifically, we will provide it with a tool to call the Wikipedia API anf to a search API for real time searches.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EiQgqoa61Ngn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ea21af-3172-4987-dbeb-1a04f31dda7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tools [WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.11/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)), DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo create a three-course Italian dinner menu that is vegetarian and incorporates cauliflower and tomatoes, I should start by searching for Italian vegetarian dishes that feature these ingredients.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Italian vegetarian dishes\u001b[0m\u001b[36;1m\u001b[1;3mPage: Vegetarian cuisine\n",
            "Summary: Vegetarian cuisine is based on food that meets vegetarian standards by not including meat and animal tissue products (such as gelatin or animal-derived rennet).\n",
            "\n",
            "Page: List of vegetable dishes\n",
            "Summary: This is a list of vegetable dishes, that includes dishes in which the main ingredient or one of the essential ingredients is a vegetable or vegetables.\n",
            "In culinary terms, a vegetable is an edible plant or its part, intended for cooking or eating raw. Many vegetable-based dishes exist throughout the world.\n",
            "\n",
            "Page: List of Indian dishes\n",
            "Summary: This is a list of Indian dishes. Many of the dishes on this list are made all across India. Indian cuisine encompasses a wide variety of regional cuisine native to India. Given the range of diversity in soil type, climate and occupations, these cuisines vary significantly from each other and use locally available ingredients such as: herbs, vegetables and fruits. The dishes are then served according to taste in either mild, medium or hot. Indian food is also heavily influenced by religious and cultural choices. \n",
            "Some Indian dishes are common in more than one region of India, with many vegetarian and vegan dishes. Some ingredients commonly found in Indian dishes include: rice, wheat, ginger, garlic, green chillies and spices.\u001b[0m\u001b[32;1m\u001b[1;3mWhile the search results provided some general information about vegetarian cuisine and vegetable dishes, they didn't specifically help me come up with a three-course Italian dinner menu that incorporates cauliflower and tomatoes. I should try searching for Italian vegetarian recipes that feature these ingredients.\n",
            "\n",
            "Action: duckduckgo_search\n",
            "Action Input: Italian vegetarian recipes with cauliflower and tomatoes\u001b[0m\u001b[33;1m\u001b[1;3mThis 30-minute pasta recipe features roasted cauliflower, amped up with Italian inspired pantry spices (oregano and crushed red chili), fresh garlic, cherry tomatoes, and plenty of olive oil. The pasta sauce is mixed right in the roasting pan, finished with a touch of cream and grated Parmesan cheese that coats the pasta like a velvety blanket. This Italian roasted cauliflower recipe makes 4 servings and is ready in 30 minutes. It has 269 calories per serving, making it a healthy and tasty choice for meals. Creamy Italian Cauliflower Soup. Enjoy the ultimate Italian comfort food with our creamy vegetable soup.It combines rich flavors and smooth textures for a satisfying meal. Ensure the cauliflower florets are completely dry before roasting. Don't overcrowd the pan, and consider a second round of roasting if needed for maximum crispiness. This recipe proves that vegetarian cooking can be both exciting and incredibly flavorful. Enjoy the satisfying crunch of the cauliflower and the rich depth of the tomato sauce ... These vegetarian Italian recipes give you so many reasons to dish up and dig in. ... shows off the colors of the Italian flag with red tomatoes, white mozzarella and fresh green basil. You'll be glad the recipe makes not one but two 13-inch pizzas! —Loretta Lawrence, Myrtle Beach, South Carolina. ... I came up with this cauliflower gnocchi ... 32+ Delicious Italian Baked Cauliflower Recipes for Every Occasion. ... Serve hot as a flavorful side or light vegetarian main dish. Italian Baked Cauliflower with Pesto and Cherry Tomatoes is a bright and savory dish that showcases the fresh flavors of Italy. This recipe is perfect for a quick weeknight dinner or as part of a larger Italian ...\u001b[0m\u001b[32;1m\u001b[1;3mBased on the search results, I can start creating a three-course Italian dinner menu that incorporates cauliflower and tomatoes. Here's a possible menu:\n",
            "\n",
            "Course 1: Creamy Italian Cauliflower Soup - This soup combines rich flavors and smooth textures for a satisfying start to the meal.\n",
            "\n",
            "Course 2: Italian Baked Cauliflower with Pesto and Cherry Tomatoes - This dish showcases the fresh flavors of Italy and can be served as a flavorful side or light vegetarian main dish.\n",
            "\n",
            "Course 3: Pasta with Roasted Cauliflower, Cherry Tomatoes, and Garlic - This 30-minute pasta recipe features roasted cauliflower, cherry tomatoes, and plenty of olive oil, mixed with a touch of cream and grated Parmesan cheese.\n",
            "\n",
            "Thought: I now know the final answer\n",
            "\n",
            "Final Answer: A possible three-course Italian dinner menu that incorporates cauliflower and tomatoes could be: \n",
            "1. Creamy Italian Cauliflower Soup\n",
            "2. Italian Baked Cauliflower with Pesto and Cherry Tomatoes\n",
            "3. Pasta with Roasted Cauliflower, Cherry Tomatoes, and Garlic.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Please help me come up with a three course Italian dinner menu. It should be vegetarian. I have cauliflower and tomatoes in my fridge.',\n",
              " 'output': 'A possible three-course Italian dinner menu that incorporates cauliflower and tomatoes could be: \\n1. Creamy Italian Cauliflower Soup\\n2. Italian Baked Cauliflower with Pesto and Cherry Tomatoes\\n3. Pasta with Roasted Cauliflower, Cherry Tomatoes, and Garlic.'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun() #实时搜索工具\n",
        "tools = load_tools([\"wikipedia\"], llm=llm) #加载绑定llm的预设工具\n",
        "tools.append(search) #把自定义搜索工具加上\n",
        "print('tools',  tools)\n",
        "# tools [WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/usr/local/lib/python3.11/dist-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)),\n",
        "# DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text'))]\n",
        "\n",
        "# create an agent with tools\n",
        "agent_with_tools = create_react_agent(llm, tools=tools, prompt=prompt)\n",
        "\n",
        "# instantiate and call the agent\n",
        "agent_executor = AgentExecutor(agent=agent_with_tools, tools=tools, verbose=True)\n",
        "agent_executor.invoke({\"input\": \"Please help me come up with a three course Italian dinner menu. It should be vegetarian. I have cauliflower and tomatoes in my fridge.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZE_nik11Ngo"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.3: LLM agents with tools</span></strong>\n",
        ">\n",
        "> 1. Please look at the code above and try to understand what it does. A list of various tools can be found here [here](https://python.langchain.com/docs/integrations/tools/).\n",
        "> 2. What steps does the agent (try to) perform in order to accomplish the task? How does it \"know\" which steps to do when? When does it execute searhces?\n",
        "> 3. Compare the results to the chain above. Do you observe differences?\n",
        "> 4. Is the Wikipedia tool a good choice for the task at hand? What else might we consider?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQqB5AKw1Ngo"
      },
      "source": [
        "```{toggle}\n",
        "> 2. The model is searching stepwise. In the firt step it searches for the whole information, getting more concrete from step to step. It even focuses on specific ingredients, like a human would do.\n",
        "> 3. The results the model found are vegetarian, using the given ingredients and are italien. Therefore, the results are better than the outputs from the models before.\n",
        "> 4. Wikipedia is interesting for theoretical information about italian food and vegetarian food, but does not provide detailed recipies. The possibilities are rather limited. Therefore, a tool concentrating on recipies might be helpful to get a better variety of recipies. Nonetheless, the results the model found are better than the results of the other models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riQ2Di511Ngo"
      },
      "source": [
        "For the sake of seeing the top possible performance of agents, we have used OpenAI models. But since they are behind a paywall, we might also want to use open-source models as a backbone for the agent. LangChain also provides integration with many [various](https://python.langchain.com/v0.1/docs/integrations/llms/) LLMs, including HuggingFace models that can be used via the HF [API endpoint](https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_endpoint/) which might not always be available and requires and HuggingFace [account](https://huggingface.co/welcome), or with a [local](https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_pipelines/) model loaded via `transformers` as we have learned. The latter requires downloading the model; since agent LLM systems require good performance of the backbone LLM, it can rather be tested with large models with at least a few billion parameters (mind their size for downloads!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wknp-m7o1Ngo"
      },
      "source": [
        "## Output parsing\n",
        "\n",
        "One of the core bottlenecks of chaining LLM calls is the potential necessity to *process outputs* in a specific (structured) way. [This](https://python.langchain.com/docs/how_to/structured_output/) page provides an overview of how this can be approached. This is step is key for enabling integration of LLMs into automatic systems where other components depend on outputs of LLMs and usually expect particular input types or formats.\n",
        "\n",
        "There are also packages / frameworks specialized in interfacing with LLMs and properly parsing their outputs like, e.g., [LMQL](https://lmql.ai/) and [this](https://github.com/microsoft/aici) controller framework from Microsoft.\n",
        "\n",
        "These resources are intended as optional useful information, in case you will explore and build your own agents; you are not expected to have looked at them in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbb9pzzz1Ngo"
      },
      "source": [
        "## Memory handling\n",
        "\n",
        "One of the main issues of agents is that they are by default *stateless*; i.e., at each step of execution there is no memory of what happened before. This is handled by adding *memory components*. An overview of this can be found [here](https://python.langchain.com/docs/how_to/chatbots_memory/#summary-memory)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDgddLJG1Ngo"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.4: Memory</span></strong>\n",
        ">\n",
        "> 1. Take a look at the approach for handling message memory above. Recall the *generative agent* architecture that was discussed in the lecture. What is the difference between this simple approach and the memory implementation in the generative agents? What are respective (dis)advantages of either approach?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}